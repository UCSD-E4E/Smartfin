{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraper to take data from CDIP at specified year/month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loosely based on tutorial at: https://towardsdatascience.com/web-scraping-html-tables-with-python-c9baba21059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#Import files\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format should be appending year, month\n",
    "# Example: Sept. 2019 -> 201909\n",
    "def create_url_string(year, month):\n",
    "    url='https://cdip.ucsd.edu/themes/cdip?tz=UTC&numcolorbands=10&palette=cdip_classic&zoom=auto&ll_fmt=dm&high=6.096&r=999&un=1&pb=1&d2=p70&u2=s:201:st:1:v:parameter:dt:'\n",
    "    if 2014 <= int(year) <= 2019:\n",
    "        year = year\n",
    "    if 1 <= int(month) <= 12 and len(month) == 2:\n",
    "        month = month\n",
    "    url += year\n",
    "    url += month\n",
    "    return url "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the year and month that you want here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cdip.ucsd.edu/themes/cdip?tz=UTC&numcolorbands=10&palette=cdip_classic&zoom=auto&ll_fmt=dm&high=6.096&r=999&un=1&pb=1&d2=p70&u2=s:201:st:1:v:parameter:dt:201909\n"
     ]
    }
   ],
   "source": [
    "url = create_url_string('2019', '09')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a handle, page, to handle the contents of the website\n",
    "page = requests.get(url)\n",
    "\n",
    "# Store the contents of the website under doc\n",
    "doc = lh.fromstring(page.content)\n",
    "\n",
    "# Parse data stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')\n",
    "\n",
    "# Check the length of the first 12 rows (should all be same)\n",
    "print([len(T) for T in tr_elements[:14]])\n",
    "\n",
    "# Need to drop the first 3 rows since they aren't in the table\n",
    "tr_elements = tr_elements[3:]\n",
    "[len(T) for T in tr_elements[:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date(UTC)\n",
      "Hs(ft)\n",
      "Tp(s)\n",
      "Dp(deg)\n",
      "Ta(s)\n",
      "SST(F)\n",
      "Air temp(F)\n",
      "['Date(UTC)', 'Hs(ft)', 'Tp(s)', 'Dp(deg)', 'Ta(s)', 'SST(F)', 'Air temp(F)']\n"
     ]
    }
   ],
   "source": [
    "# Parse the first row as the header\n",
    "tr_elements = doc.xpath('//tr')\n",
    "\n",
    "# Create empty list\n",
    "headers = []\n",
    "i = 0\n",
    "\n",
    "# For each row, store each first element (header) and an empty list\n",
    "for t in tr_elements[3]:\n",
    "    i+=1\n",
    "    name=t.text_content()\n",
    "    print(name)\n",
    "    headers.append(name)\n",
    "\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rows(row_number):\n",
    "    name_string = \"\"\n",
    "    name_list = []\n",
    "    for t in tr_elements[row_number]:\n",
    "        name = t.text_content()\n",
    "        for i in name: \n",
    "            name_string += i\n",
    "    #print(name_string)\n",
    "\n",
    "    # Create a string from the values\n",
    "    name_string = name_string.split(\" \")\n",
    "    \n",
    "    # Remove all spaces from the list\n",
    "    for i in name_string: \n",
    "        if len(i) > 0:\n",
    "            name_list.append(i)\n",
    "      \n",
    "    # Ensure that time stays with 'Date (UTC)'' header\n",
    "    name_list[0] = name_list[0] + \" \" +  name_list[1]\n",
    "    name_list.pop(1)\n",
    "    \n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-09-30 23:32', '3.54', '7.69', '285', '6.01', '71.2', '68.4']\n"
     ]
    }
   ],
   "source": [
    "# The first row that cna be parsed starts at 4\n",
    "name_list = parse_rows(4)\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date(UTC) Hs(ft) Tp(s) Dp(deg) Ta(s) SST(F) Air temp(F)\n",
      "0  2019-09-30 23:32   3.54  7.69     285  6.01   71.2        68.4\n",
      "1  2019-09-30 23:02   3.41  7.69     282  6.16   71.2        68.2\n",
      "2  2019-09-30 22:32   3.48  7.69     282  6.11   71.2        67.6\n",
      "3  2019-09-30 22:02   3.41  7.14     281  6.14   71.4        67.1\n",
      "4  2019-09-30 21:32   3.41  8.33     285  6.13   71.2        66.9\n",
      "5  2019-09-30 21:02   3.28  8.33     284  6.15   70.9        66.7\n",
      "6  2019-09-30 20:32   3.28  7.69     284  6.04   70.9        66.4\n",
      "7  2019-09-30 20:02   3.38  7.14     284  5.82   70.9        65.8\n",
      "8  2019-09-30 19:32   3.15  7.69     284  5.85   70.7        65.3\n",
      "9  2019-09-30 19:02   3.18  5.88     285  5.60   70.7        65.1\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas dataframe: \n",
    "data_list = []\n",
    "\n",
    "#Since out first row is the header, data is stored on the second row onwards\n",
    "for j in range(4, len(tr_elements)):\n",
    "    data = parse_rows(j)\n",
    "    data_list.append(data)\n",
    "\n",
    "df_data = pd.DataFrame(data_list, columns=headers)\n",
    "print(df_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. If you want to find the data corresponding to the closest time as the surf session that you're interested in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_time(date, time_utc):\n",
    "    time_list = []\n",
    "    \n",
    "    # Iterate over each date\n",
    "    for x in df_data['Date(UTC)']:\n",
    "        # Choose all timestamps within the same hour\n",
    "        a = x.split(\" \")\n",
    "        if date == a[0]:\n",
    "            a = str(a[1]).split(':')\n",
    "            y = str(time_utc).split(\":\")\n",
    "            if a[0] == y[0]:\n",
    "                time_string = str(a[0]) + \":\" + str(a[1])\n",
    "                time_list.append(time_string)\n",
    "    return time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-30 23:32\n",
      "['2019-09-30', '23:32']\n",
      "[\"['2019-09-30', '23\", \"32']\"]\n"
     ]
    }
   ],
   "source": [
    "print(df_data['Date(UTC)'][0])\n",
    "x = df_data['Date(UTC)'][0].split(\" \")\n",
    "print(x)\n",
    "x = str(x).split(':')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19:32', '19:02']\n"
     ]
    }
   ],
   "source": [
    "date = '2019-09-30'\n",
    "time_list = find_closest_time(date, '19:05')\n",
    "print(time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you can do something like compute the average wave height for the one hour time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    }
   ],
   "source": [
    "print(df_data['Date(UTC)'].size)\n",
    "length = df_data['Date(UTC)'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3.15'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-6d495be87a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date(UTC)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m#print(df_data['Hs(ft)'][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mwave_height_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hs(ft)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwave_height_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '3.15'"
     ]
    }
   ],
   "source": [
    "wave_height_list = []\n",
    "for time in time_list: \n",
    "    date_data = date + \" \" + time\n",
    "    for i in range(0, length):\n",
    "        if df_data['Date(UTC)'][i] == date_data:\n",
    "            #print(df_data['Hs(ft)'][i])\n",
    "            wave_height_list.append(int(df_data['Hs(ft)'][i])\n",
    "print(wave_height_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
